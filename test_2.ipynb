{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'CFG2' from 'utils' (/Users/gere/Desktop/myfolder/desktop/fall2022/Vision and Image/Parasitic-Egg-Detection-and-Classification/utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mread_dataset\u001b[39;00m \u001b[39mimport\u001b[39;00m build_df\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m CFG2\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n\u001b[1;32m      8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'CFG2' from 'utils' (/Users/gere/Desktop/myfolder/desktop/fall2022/Vision and Image/Parasitic-Egg-Detection-and-Classification/utils.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from read_dataset import build_df\n",
    "from utils import CFG2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from models import *\n",
    "from main import *\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from datapreprocess import *\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import *\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "import torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_FILES = CFG2.img_path \n",
    "LABEL_FILES = CFG2.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reader(IMG_FILES,LABEL_FILES):\n",
    "    # x_train, x_valid, x_test, y_train, y_valid, y_test\n",
    "    dir_names = ['train','valid','test']\n",
    "    # images\n",
    "    x_train, x_valid, x_test, y_train, y_valid, y_test=[],[],[],[],[],[]\n",
    "    for dir in os.listdir(IMG_FILES):\n",
    "        if dir in dir_names:\n",
    "            for img_name in os.listdir(os.path.join(IMG_FILES, dir)):\n",
    "                img_path = os.path.join(IMG_FILES, dir, img_name)\n",
    "\n",
    "                if dir  == 'train':\n",
    "                    x_train.append(img_path)\n",
    "\n",
    "                elif dir == 'valid':\n",
    "                    x_valid.append(img_path)\n",
    "\n",
    "                elif dir  == 'test':\n",
    "                    x_test .append(img_path)\n",
    "    \n",
    "    for l_dir in os.listdir(LABEL_FILES):\n",
    "        if l_dir in dir_names:\n",
    "            for label in (os.listdir(os.path.join(LABEL_FILES, l_dir))):\n",
    "                label_path = os.path.join(LABEL_FILES, l_dir,label)\n",
    "\n",
    "                if l_dir  == 'train':\n",
    "                    y_train.append(label_path)\n",
    "\n",
    "                elif l_dir == 'valid':\n",
    "                    y_valid.append(label_path)\n",
    "\n",
    "                elif l_dir  == 'test':\n",
    "                    y_test .append(label_path)\n",
    "\n",
    "    train_data = [x_train,y_train]\n",
    "    valid_data = [x_valid,y_valid]\n",
    "    test_data = [x_test,y_test]\n",
    "    return np.array(train_data), np.array(valid_data), np.array(test_data)\n",
    "\n",
    "    # class labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data= reader(IMG_FILES, LABEL_FILES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mCustom_Dataset\u001b[39;00m(torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataset):\n\u001b[1;32m      2\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, data, transform\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,IMAGE_SIZE \u001b[39m=\u001b[39m \u001b[39m640\u001b[39m):\n\u001b[1;32m      3\u001b[0m         \u001b[39msuper\u001b[39m(Custom_Dataset, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "class Custom_Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, transform=None,IMAGE_SIZE = 640):\n",
    "        super(Custom_Dataset, self).__init__()\n",
    "        # List of files\n",
    "        self.IMAGE_SIZE = IMAGE_SIZE\n",
    "        self.data_files = data[0]  # [DATA_FOLDER.format(id) for id in ids]\n",
    "        self.label_files = data[1]  # [LABELS_FOLDER.format(id) for id in ids]\n",
    "        self.class_labels = torch.LongTensor(self.get_class_labels()) \n",
    "        self.transform = transform\n",
    "        # Sanity check : raise an error if some files do not exist\n",
    "        for f in self.data_files:\n",
    "            if not os.path.isfile(f):\n",
    "                raise KeyError(\"{} is not a file !\".format(f))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_files)  # the length of the used data\n",
    "    \n",
    "    def img_size(self,idx):\n",
    "        self.img =np.asarray(io.imread(self.data_files[idx]))\n",
    "        return (self.img).shape\n",
    "    \n",
    "    def get_class_labels(self):\n",
    "        labels  = []\n",
    "        for fname in self.label_files:\n",
    "            with open(fname, \"r\") as file:\n",
    "                labels.append(file.read().split(\" \")[0])\n",
    "        return np.array(labels,dtype=np.uint8)\n",
    "\n",
    "    def original_img(self,idx):\n",
    "        self.img =(\n",
    "                   1/255\n",
    "             *np.asarray(\n",
    "                io.imread(self.data_files[idx], plugin=\"pil\").transpose(\n",
    "                    (2, 0, 1)\n",
    "                ),\n",
    "                dtype=\"float32\",\n",
    "            )\n",
    "        )\n",
    "        return self.img,self.labels[idx]\n",
    "\n",
    "    def get_class_label(self,idx):\n",
    "        return self.class_labels[idx]\n",
    "\n",
    "    def resized_bbox(self,idx):\n",
    "        image = Chitra(self.data_files[idx], self.labels[idx], self.class_labels[idx])\n",
    "        # Chitra can rescale your bounding box automatically based on the new image size.\n",
    "        image.resize_image_with_bbox((640, 640))\n",
    "\n",
    "        return np.array([image.bboxes[0].x1_int,image.bboxes[0].y1_int,image.bboxes[0].x2_int,image.bboxes[0].y2_int])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #         Pre-processing steps\n",
    "        \n",
    "        if self.transform is not None:\n",
    "\n",
    "            self.data = (\n",
    "                np.asarray(\n",
    "                io.imread(self.data_files[idx], plugin=\"pil\").transpose(\n",
    "                    (2, 0, 1)\n",
    "                ),\n",
    "                dtype=\"float32\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "            # convert the tensor to image\n",
    "            tensor2image_transform = transforms.ToPILImage()\n",
    "\n",
    "            # make the format avialble to resnet model\n",
    "            data_p = torch.tensor(\n",
    "                self.data \n",
    "            )  # tranform the image into ResNet format\n",
    "\n",
    "            image = tensor2image_transform(data_p)\n",
    "            data_p = self.transform(\n",
    "                image\n",
    "            )  # transform the image into ResNet format\n",
    "            return data_p, self.class_labels[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"gets gpu for mac m1 or cuda, or cpu machine\"\"\"\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "        print('Running on Cuda GPU')\n",
    "        return device\n",
    "        # x = torch.ones(1, device=mps_device)\n",
    "        # print(x)\n",
    "        \n",
    "    \n",
    "    elif torch.backends.mps.is_available():\n",
    "        print('Running on the Mac GPU')\n",
    "        mps_device = torch.device(\"mps\")\n",
    "        return mps_device\n",
    "        \n",
    "    else:\n",
    "        # print(\"MPS device not found.\")\n",
    "        return torch.device('cpu')\n",
    "        print('Code Running on a CPU')\n",
    "\n",
    "\n",
    "\n",
    "def plot_model_history(training_accs, training_losses):# Get training and test loss histories\n",
    "\n",
    "    # Create count of the number of epochs\n",
    "    epoch_count = range(1, len(training_accs) + 1)\n",
    "\n",
    "    # Visualize loss history\n",
    "    plt.plot(epoch_count, training_losses, 'r--')\n",
    "    plt.plot(epoch_count, training_accs, 'b-')\n",
    "    plt.legend(['Training Loss', 'Training Accuracy'])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy and Loss Curves')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# testing/ validation of unet model\n",
    "def validate_model(trained_model, test_dataloader, device=None):\n",
    "    trained_model.eval() # switch off some layers such as dropout layer during validation\n",
    "    with torch.no_grad():\n",
    "        test_predictions = []\n",
    "        test_labels = []\n",
    "\n",
    "        for i, (x, y) in enumerate(test_dataloader):\n",
    "            x  = x.to(device)\n",
    "            y  = y.to(device)\n",
    "            y_hat = trained_model(x)\n",
    "            predicted_labels =  torch.argmax(y_hat, dim=1).detach().cpu().numpy().tolist()\n",
    "            # y_hat  = y_hat.cpu()\n",
    "            y = y.detach().cpu().numpy().tolist()\n",
    "            test_predictions.extend(predicted_labels)\n",
    "            test_labels.extend(y)\n",
    "    \n",
    "        return test_labels, test_predictions\n",
    "\n",
    "\n",
    "def evalution_metrics(ground_truth, predictions):\n",
    "    print(f\"mean acc score = {accuracy_score(ground_truth, predictions)}\")\n",
    "    print(f\"mean recall score = {recall_score(ground_truth, predictions, average='micro')}\")\n",
    "    print(f\"precision score = {precision_score(ground_truth, predictions, average='micro')}\")\n",
    "    print(f\"mean f1 score = {f1_score(ground_truth, predictions, average='micro')}\")\n",
    "    labels = np.unique(ground_truth).tolist()\n",
    "    cm  = confusion_matrix(ground_truth, predictions, labels=labels) \n",
    "    report  = classification_report(ground_truth, predictions)\n",
    "    print(report)\n",
    "\n",
    "    sns.heatmap(cm)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = preprocess_image()\n",
    "train_dataset  = Custom_Dataset(train_data, transform=transform)\n",
    "valid_dataset = Custom_Dataset(valid_data, transform=transform)\n",
    "test_dataset = Custom_Dataset(test_data, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = get_default_device()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.001\n",
    "EPOCHS = 20\n",
    "# Parameters\n",
    "params = {\"batch_size\": 16, \"shuffle\": True, \"num_workers\": 4}\n",
    "NUM_CLASSES = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dataloaders\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, params[\"batch_size\"], num_workers=params[\"num_workers\"], shuffle=params[\"shuffle\"],\n",
    ")\n",
    "validation_dataloader = DataLoader(valid_dataset, params['batch_size'],num_workers=params['num_workers'])\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, params[\"batch_size\"], num_workers=params[\"num_workers\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_channels=3, filters=32, num_classes=11):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1  = nn.Conv2d(input_channels, filters, kernel_size=2) \n",
    "        self.conv2  = nn.Conv2d(filters, filters * 2, kernel_size=3)\n",
    "        self.conv3 = nn.Conv2d(filters * 2, filters * 4, kernel_size=3)\n",
    "\n",
    "        # self.fc1  =  nn.Linear(in_features=  (filters * 4 * 28*28  + 2048) , out_features=64)\n",
    "        self.out = nn.Linear(in_features=filters * 4 * 28*28  + 2048, out_features=num_classes)\n",
    "\n",
    "        self.flatten = nn.Flatten(start_dim=1)\n",
    "\n",
    "    def forward(self, x, x2):\n",
    "        x  = self.conv1(x) # output = (B, C,224,224)\n",
    "        x  = F.relu(x) \n",
    "        x  = F.max_pool2d(x, kernel_size=2, padding=1) #output = (B,C,112,112)\n",
    "        x  = F.dropout(x, 0.2)\n",
    "\n",
    "        x  = self.conv2(x) #output = (B,iC,112,112)\n",
    "        x  = F.relu(x)\n",
    "        x  = F.max_pool2d(x, kernel_size=2, padding=1) # #output = (B,iC,56,56)\n",
    "        x  = F.dropout(x, 0.2)\n",
    "        x  = self.conv3(x)\n",
    "        x  = F.relu(x)\n",
    "        x  = F.max_pool2d(x, kernel_size=2, padding=1) # output = (B, iC, 28 , 28)\n",
    "        x  = F.dropout(x, 0.2)\n",
    "        x  = self.flatten(x)\n",
    "        # print(\"x2 size = \", x2.size())\n",
    "        # print(\n",
    "        #     'size of x  = ', x.size(),\n",
    "        # )\n",
    "        x2  = self.flatten(x2)\n",
    "        x  = torch.cat((x, x2), dim=1)\n",
    "        # print(\"cat size = \", x.size())\n",
    "        # x  = self.fc1(x)\n",
    "        # x  = F.relu(x)\n",
    "        x  = F.dropout(x, 0.25)\n",
    "        x  = self.out(x)\n",
    "        x  = F.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pretrained_model():\n",
    "    \n",
    "    resnet152 = torchvision.models.resnet152(pretrained=True)\n",
    "    resnet152.eval()\n",
    "    # remove the last layer\n",
    "    resnet152_model = torch.nn.Sequential(*(list(resnet152.children())[:-1]))\n",
    "    # freeze the model\n",
    "    for param in resnet152_model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "\n",
    "    return resnet152_model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def trainCustomModel(resnetModel,yoloDetectModel,customCNNModel, train_dataloader, optimizer,loss_fn,in_channels=3,num_classes=11, epochs=30, learning_rate=0.001, device='cpu'):\n",
    "    \"\"\"Accepts feature from resnet \n",
    "    and yolo object detection cropped iamge(s) \n",
    "    as features to train an accurate cnn classifier.\n",
    "    \"\"\"\n",
    "\n",
    "    training_losses = []\n",
    "    training_accs = []\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        number_of_batches = 0\n",
    "        epoch_loss_values = 0.0\n",
    "        epoch_accs = 0.0\n",
    "        for index, batch in enumerate(tqdm(train_dataloader)):\n",
    "            # X,  y = X.to(device), y.to(device)  # make the tensors in gpu state\n",
    "            X  = Variable(batch[0], requires_grad=True).to(device)\n",
    "            y  = torch.LongTensor(batch[1]).to(device)\n",
    "\n",
    "            # X_valid  = Variable(valid_batch[0], requires_grad=False).to(device)\n",
    "            # y_valid = torch.LongTensor(valid_batch[1]).to(device)\n",
    "\n",
    "            # resnet processing\n",
    "            # # resnet_X = Variable(resnet_preprocess((X.cpu())), requires_grad=True).to(device)\n",
    "            # print('Before Resnt')\n",
    "            resnet_X  = resnetModel(X)\n",
    "            # print('After Resnt')\n",
    "\n",
    "            # extracted_features = resnetModel(resnet_X) # (Bacth, 1000) tensor is returned\n",
    "            # X2  = Variable(torch.randn(size= (X.size()[0],1000)), requires_grad=True).to(device)\n",
    "            preds = customCNNModel(X, resnet_X)\n",
    "            # print('After customCNNModel')\n",
    "        \n",
    "\n",
    "            loss = loss_fn(preds, y).to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            probs = torch.log_softmax(preds, dim=1)\n",
    "            predicted_labels = torch.argmax(probs, dim=1)\n",
    "\n",
    "            # acc\n",
    "            epoch_accs += accuracy_score(y.detach().cpu(),predicted_labels.detach().cpu())\n",
    "            epoch_loss_values += loss.item()\n",
    "\n",
    "            number_of_batches += 1\n",
    "\n",
    "        # compute average of batch loss and accuracy\n",
    "        batch_acc, batch_loss = epoch_accs / \\\n",
    "            number_of_batches, epoch_loss_values / number_of_batches\n",
    "        training_losses.append(batch_loss)\n",
    "        training_accs.append(batch_acc)\n",
    "\n",
    "        print(\"Epoch:{}/{}, acc={:.3f}%, loss={:.3f}\".format(epoch,epochs, batch_acc*100, batch_loss))\n",
    "\n",
    "    print(\"Learning Finished!\")\n",
    "\n",
    "    return training_accs, training_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_CHANNELS  = 3\n",
    "NUM_FEATURES  = 8\n",
    "customCNNModel = CNN(INPUT_CHANNELS, NUM_FEATURES, NUM_CLASSES).to(DEVICE) \n",
    "optimizer = torch.optim.Adam(\n",
    "        params=customCNNModel.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnetModel  = get_pretrained_model().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data  = torch.randn(size = (3, 3, 224, 224)).to(DEVICE)\n",
    "# out  = resnetModel(test_data)\n",
    "# out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_out  = torch.nn.Flatten(start_dim=1)(out)\n",
    "# new_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_accs, training_losses = trainCustomModel(resnetModel, None,customCNNModel, train_dataloader, optimizer,loss_fn, in_channels=3,num_classes=11, epochs=3, learning_rate=0.001, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_history(training_accs, training_losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "552c9644091b0c8a03658003f6bc4e6be186a8b6576a345edbde5d33b7af3828"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
