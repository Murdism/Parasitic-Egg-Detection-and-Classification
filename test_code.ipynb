{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from read_dataset import build_df\n",
    "from utils import CFG\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from datapreprocess import preprocess_image\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import *\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "import torchvision\n",
    "from utils import CFG2\n",
    "\n",
    "\n",
    "# Parameters\n",
    "params = {\"batch_size\": 8, \"shuffle\": True, \"num_workers\": 4}\n",
    "NUM_CLASSES = 11\n",
    "\n",
    "\n",
    "images_folder  = CFG2.imgs_path\n",
    "labels_folder = CFG2.labels_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import CNN, tinyCNN,NeuralNet, get_pretrained_model\n",
    "from helper_tools import reader, evalution_metrics, validate_model, get_default_device, trainCustomModel, plot_model_history\n",
    "from helper_tools import CustomDatasetV2 as CustomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, validation_data, test_data = reader(images_folder, labels_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0][:5], train_data[1][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform  = preprocess_image\n",
    "train_dataset  = CustomDataset(train_data, transform_fn=transform)\n",
    "validation_dataset = CustomDataset(validation_data, transform_fn=transform)\n",
    "\n",
    "test_dataset = CustomDataset(test_data, transform_fn=transform)\n",
    "np.max(np.array(train_dataset[9][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(np.array(train_dataset[9][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = get_default_device()\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.001\n",
    "EPOCHS = 2\n",
    "\n",
    "# Parameters\n",
    "params = {\"batch_size\": 8, \"shuffle\": True, \"num_workers\": 4}\n",
    "max_epochs = 100\n",
    "NUM_CLASSES = 11\n",
    "RESNET_OUT_FEATURES = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dataloaders\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, params[\"batch_size\"], num_workers=params[\"num_workers\"], shuffle=params[\"shuffle\"],\n",
    ")\n",
    "validation_dataloader = torch.utils.data.DataLoader(validation_dataset, params['batch_size'],num_workers=params['num_workers'])\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, params[\"batch_size\"], num_workers=params[\"num_workers\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnetModel  = get_pretrained_model().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(train_dataset[0][0].permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_tiny_cnn(model, train_dataloader,loss_fn, epochs=30, learning_rate=0.001, device='cpu'):\n",
    "    \"\"\"Accepts feature from resnet and yolo object detection cropped iamge(s) \n",
    "    as features to train an accurate cnn classifier.\n",
    "    \"\"\"\n",
    "    # custom_cnn_classifier = tinyCNN(3, 32, 11).to(device)\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
    "\n",
    "    training_losses = []\n",
    "    training_accs = []\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        number_of_batches = 0\n",
    "        epoch_loss_values = 0.0\n",
    "        epoch_accs = 0.0\n",
    "        for index, (X, y) in enumerate(tqdm(train_dataloader)):\n",
    "            \n",
    "            X  = Variable(X, requires_grad=True).to(device)\n",
    "            \n",
    "            y  = y.to(device)\n",
    "\n",
    "            # predict using resnet\n",
    "            # resnet_X = resnet_model(X)\n",
    "            preds = model(X)\n",
    "            # print(\"preds\",preds)\n",
    "        \n",
    "            loss = loss_fn(preds, y).to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            probs = torch.log_softmax(preds, dim=1)\n",
    "            predicted_labels = torch.argmax(probs, dim=1)\n",
    "            # print(\"predicted_labels\",predicted_labels)\n",
    "\n",
    "            # acc\n",
    "            epoch_accs += accuracy_score(y.detach().cpu(),predicted_labels.detach().cpu())\n",
    "            epoch_loss_values += loss.item()\n",
    "\n",
    "            number_of_batches += 1\n",
    "\n",
    "            # acc, accuracy\n",
    "        batch_acc, batch_loss = epoch_accs / \\\n",
    "            number_of_batches, epoch_loss_values / number_of_batches\n",
    "        training_losses.append(batch_loss)\n",
    "        training_accs.append(batch_acc)\n",
    "\n",
    "        print(\"Epoch:{}/{}, acc={:.3f}%, loss={:.3f}\".format(epoch, epochs, batch_acc*100, batch_loss))\n",
    "\n",
    "    print(\"Learning Finished!\")\n",
    "\n",
    "    return model, training_accs, training_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters  = 32\n",
    "in_channels  = 3\n",
    "\n",
    "resnetModel = get_pretrained_model().to(DEVICE)\n",
    "yolov7Model  = None #get_yolov7_model().to(DEVICE)\n",
    "custom_cnn_model  = CNN(in_channels, filters, NUM_CLASSES).to(DEVICE)\n",
    "\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(params=custom_cnn_model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model, training_accs, training_losses = trainCustomModel(resnetModel, yolov7Model, custom_cnn_model, train_dataloader, optimizer,loss_fn, epochs=2, learning_rate=0.001, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_tiny_cnn_model = tinyCNN(in_channels, filters, NUM_CLASSES).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "resnet_152  = get_pretrained_model().to(DEVICE)\n",
    "neural_net_model = NeuralNet().to(DEVICE)\n",
    "finetuned_resnet152_model  = nn.Sequential(resnet_152, neural_net_model).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_resnet152_model, training_accs, training_losses = train_tiny_cnn(finetuned_resnet152_model, train_dataloader,loss_fn, epochs = 50, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_accs, training_losses = train_tiny_cnn(train_dataloader,loss_fn, epochs=50, learning_rate=0.001, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_history(training_accs, training_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels, test_predictions  = validate_model(finetuned_resnet152_model, test_dataloader, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalution_metrics(test_labels, test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(os.getcwd(),'models_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(finetuned_resnet152_model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customCNNModel.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_model.state_dict()\n",
    "\n",
    "# model = CNN(3, 32, NUM_CLASSES).to(DEVICE)\n",
    "# model.load_state_dict(torch.load(path))\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.state_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "validate_model(custom_cnn_classifier, test_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('mujoco_py')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a2f424a28026550c59ba80030c3368e53b944a64380b7979f5e4c49b470b0842"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
