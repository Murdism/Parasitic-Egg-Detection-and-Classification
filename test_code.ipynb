{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from read_dataset import build_df\n",
    "from utils import CFG\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from datapreprocess import preprocess_image\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import *\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "import torchvision\n",
    "from utils import CFG2\n",
    "\n",
    "\n",
    "# Parameters\n",
    "params = {\"batch_size\": 8, \"shuffle\": True, \"num_workers\": 4}\n",
    "NUM_CLASSES = 11\n",
    "\n",
    "\n",
    "images_folder  = CFG2.imgs_path\n",
    "labels_folder = CFG2.labels_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_tools import CustomDataset,  CNN, tinyCNN\n",
    "from helper_tools import reader, evalution_metrics, validate_model, get_default_device, trainCustomModel, plot_model_history, get_pretrained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, validation_data, test_data = reader(images_folder, labels_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['cell_dataset/images/train/Ascaris lumbricoides_0005.jpg',\n",
       "        'cell_dataset/images/train/Ascaris lumbricoides_0006.jpg',\n",
       "        'cell_dataset/images/train/Ascaris lumbricoides_0007.jpg',\n",
       "        'cell_dataset/images/train/Ascaris lumbricoides_0008.jpg',\n",
       "        'cell_dataset/images/train/Ascaris lumbricoides_0009.jpg'],\n",
       "       dtype=object),\n",
       " array(['cell_dataset/labels/train/Ascaris lumbricoides_0005.txt',\n",
       "        'cell_dataset/labels/train/Ascaris lumbricoides_0006.txt',\n",
       "        'cell_dataset/labels/train/Ascaris lumbricoides_0007.txt',\n",
       "        'cell_dataset/labels/train/Ascaris lumbricoides_0008.txt',\n",
       "        'cell_dataset/labels/train/Ascaris lumbricoides_0009.txt'],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][:5], train_data[1][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3585434"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datapreprocess as dp\n",
    "transform  = preprocess_image\n",
    "train_dataset  = CustomDataset(train_data, transform=transform)\n",
    "validation_dataset = CustomDataset(validation_data, transform=transform)\n",
    "\n",
    "test_dataset = CustomDataset(test_data, transform=transform)\n",
    "np.max(np.array(train_dataset[9][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.2274169"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(np.array(train_dataset[9][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on Cuda GPU\n"
     ]
    }
   ],
   "source": [
    "DEVICE = get_default_device()\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.001\n",
    "EPOCHS = 2\n",
    "\n",
    "# Parameters\n",
    "params = {\"batch_size\": 8, \"shuffle\": True, \"num_workers\": 4}\n",
    "max_epochs = 100\n",
    "NUM_CLASSES = 11\n",
    "RESNET_OUT_FEATURES = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dataloaders\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, params[\"batch_size\"], num_workers=params[\"num_workers\"], shuffle=params[\"shuffle\"],\n",
    ")\n",
    "validation_dataloader = torch.utils.data.DataLoader(validation_dataset, params['batch_size'],num_workers=params['num_workers'])\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, params[\"batch_size\"], num_workers=params[\"num_workers\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_labels, test_predictions = validate_model(trained_model, test_dataloader, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, path=None):\n",
    "    if path is not None:\n",
    "        torch.save(model.state_dict(), path)\n",
    "    else:\n",
    "        curr_dir  = os.getcwd()\n",
    "        torch.save(model.state_dict(), curr_dir)\n",
    "\n",
    "\n",
    "def load_model(model_weights, path):\n",
    "\n",
    "    model = NeuralNet()\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model.eval()\n",
    "\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn_model = CNN(3,32,11)\n",
    "# test_data  = torch.randn(size = (10, 3, 224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary(cnn_model, (test_data, torch.tensor(torch.randn(10, 1000))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom_cnn_classifier = CNN(input_channels=3, filters=16, num_classes=NUM_CLASSES).to(DEVICE) \n",
    "# optimizer = torch.optim.Adam(params=custom_cnn_classifier.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnetModel  = get_pretrained_model().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1.2043, 1.3755, 1.3927,  ..., 1.3242, 1.2385, 1.1187],\n",
       "          [1.3755, 1.3413, 1.2728,  ..., 1.2385, 1.1872, 1.2043],\n",
       "          [1.2557, 1.2728, 1.2385,  ..., 1.3242, 1.3070, 1.3584],\n",
       "          ...,\n",
       "          [1.1700, 1.1700, 1.0502,  ..., 1.3413, 1.4098, 1.1187],\n",
       "          [1.0673, 1.0673, 0.9988,  ..., 1.3927, 1.4612, 0.3481],\n",
       "          [1.2043, 1.2385, 1.2557,  ..., 1.3584, 1.2385, 1.0673]],\n",
       " \n",
       "         [[1.5882, 1.8508, 1.8508,  ..., 1.9034, 1.8508, 1.7458],\n",
       "          [1.7458, 1.6933, 1.6933,  ..., 1.9209, 1.7808, 1.6933],\n",
       "          [1.6408, 1.7283, 1.6232,  ..., 1.8158, 1.7808, 1.7458],\n",
       "          ...,\n",
       "          [1.6232, 1.7108, 1.6232,  ..., 1.8683, 1.9384, 1.5707],\n",
       "          [1.7108, 1.7458, 1.6583,  ..., 1.7283, 1.8508, 0.9055],\n",
       "          [1.6933, 1.7108, 1.7808,  ..., 1.7283, 1.6232, 1.5882]],\n",
       " \n",
       "         [[1.7860, 2.0125, 1.9951,  ..., 1.8905, 1.8905, 1.8905],\n",
       "          [1.9080, 1.8731, 1.8731,  ..., 1.8208, 1.8383, 1.8731],\n",
       "          [1.7511, 1.8557, 1.8383,  ..., 1.9080, 1.8557, 1.8383],\n",
       "          ...,\n",
       "          [1.8208, 1.8731, 1.7511,  ..., 1.9951, 1.9080, 1.3851],\n",
       "          [1.9080, 1.8383, 1.7337,  ..., 1.9428, 1.9080, 0.9145],\n",
       "          [1.8731, 1.8208, 1.9254,  ..., 1.9603, 1.7685, 1.7163]]]),\n",
       " tensor(0))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(train_dataset[0][0].permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_tiny_cnn(model, train_dataloader,loss_fn, epochs=30, learning_rate=0.001, device='cpu'):\n",
    "    \"\"\"Accepts feature from resnet and yolo object detection cropped iamge(s) \n",
    "    as features to train an accurate cnn classifier.\n",
    "    \"\"\"\n",
    "    # custom_cnn_classifier = tinyCNN(3, 32, 11).to(device)\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
    "\n",
    "    training_losses = []\n",
    "    training_accs = []\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        number_of_batches = 0\n",
    "        epoch_loss_values = 0.0\n",
    "        epoch_accs = 0.0\n",
    "        for index, (X, y) in enumerate(tqdm(train_dataloader)):\n",
    "            \n",
    "            X  = Variable(X, requires_grad=True).to(device)\n",
    "            \n",
    "            y  = y.to(device)\n",
    "\n",
    "            # predict using resnet\n",
    "            # resnet_X = resnet_model(X)\n",
    "            preds = model(X)\n",
    "            # print(\"preds\",preds)\n",
    "        \n",
    "            loss = loss_fn(preds, y).to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            probs = torch.log_softmax(preds, dim=1)\n",
    "            predicted_labels = torch.argmax(probs, dim=1)\n",
    "            # print(\"predicted_labels\",predicted_labels)\n",
    "\n",
    "            # acc\n",
    "            epoch_accs += accuracy_score(y.detach().cpu(),predicted_labels.detach().cpu())\n",
    "            epoch_loss_values += loss.item()\n",
    "\n",
    "            number_of_batches += 1\n",
    "\n",
    "            # acc, accuracy\n",
    "        batch_acc, batch_loss = epoch_accs / \\\n",
    "            number_of_batches, epoch_loss_values / number_of_batches\n",
    "        training_losses.append(batch_loss)\n",
    "        training_accs.append(batch_acc)\n",
    "\n",
    "        print(\"Epoch:{}/{}, acc={:.3f}%, loss={:.3f}\".format(epoch, epochs, batch_acc*100, batch_loss))\n",
    "\n",
    "    print(\"Learning Finished!\")\n",
    "\n",
    "    return model, training_accs, training_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters  = 32\n",
    "in_channels  = 3\n",
    "\n",
    "resnetModel = get_pretrained_model().to(DEVICE)\n",
    "yolov7Model  = None #get_yolov7_model().to(DEVICE)\n",
    "custom_cnn_model  = CNN(in_channels, filters, NUM_CLASSES).to(DEVICE)\n",
    "\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(params=custom_cnn_model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 983/983 [02:04<00:00,  7.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1/2, acc=8.545%, loss=2.449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 983/983 [02:09<00:00,  7.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:2/2, acc=8.520%, loss=2.407\n",
      "Learning Finished!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m training_accs, training_losses \u001b[39m=\u001b[39m trainCustomModel(resnetModel, yolov7Model, custom_cnn_model, train_dataloader, optimizer,loss_fn, epochs\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, learning_rate\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m, device\u001b[39m=\u001b[39mDEVICE)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "custom_model, training_accs, training_losses = trainCustomModel(resnetModel, yolov7Model, custom_cnn_model, train_dataloader, optimizer,loss_fn, epochs=2, learning_rate=0.001, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_tiny_cnn_model = tinyCNN(in_channels, filters, NUM_CLASSES).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, in_features=2048, num_classes = 11):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1  =  nn.Linear(in_features=in_features, out_features=num_classes)\n",
    "        self.flatten  = nn.Flatten(start_dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x  = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "resnet_152  = get_pretrained_model().to(DEVICE)\n",
    "neural_net_model = NeuralNet().to(DEVICE)\n",
    "finetuned_resnet152_model  = nn.Sequential(resnet_152, neural_net_model).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_resnet152_model, training_accs, training_losses = train_tiny_cnn(finetuned_resnet152_model, train_dataloader,loss_fn, epochs = 50, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_accs, training_losses = train_tiny_cnn(train_dataloader,loss_fn, epochs=50, learning_rate=0.001, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_history(training_accs, training_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels, test_predictions  = validate_model(finetuned_resnet152_model, test_dataloader, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalution_metrics(test_labels, test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(os.getcwd(),'models_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(finetuned_resnet152_model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customCNNModel.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_model.state_dict()\n",
    "\n",
    "# model = CNN(3, 32, NUM_CLASSES).to(DEVICE)\n",
    "# model.load_state_dict(torch.load(path))\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.state_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "validate_model(custom_cnn_classifier, test_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('mujoco_py')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a2f424a28026550c59ba80030c3368e53b944a64380b7979f5e4c49b470b0842"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
