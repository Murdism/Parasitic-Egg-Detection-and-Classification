{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The original dataset contains 10927 images of 11 classes,each of which contains around 1,000 examples.\n",
    " We randomly select 875 examples with each class contributing 8% of its images to construct validation set \n",
    " the test set contains 20% of the images stratified by class\n",
    "The rest of original dataset is our training set,i.e., the training-validation ratiois 9:1. while trainining test ratio is 4:1\n",
    "'''\n",
    "import torch \n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from read_dataset import build_df\n",
    "from utils import CFG\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(train,target,validation=True):\n",
    "    #70%-20%-10% split, as we're splitting 10% from the already split X_train so we're actually ending up with a 72%-20%-8% split here:\n",
    "    #80 -20\n",
    "    # x = img_path\n",
    "    # y = 'xmin', 'ymin', 'xmax', 'ymax', 'label'\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        train, target, train_size=0.8, shuffle=True, stratify=target[:, 4]\n",
    "    )\n",
    "    test_data = [X_test, y_test]\n",
    "    if validation:\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            train_size=0.9,\n",
    "            shuffle=True,\n",
    "            stratify=y_train[:, 4],\n",
    "        )\n",
    "        train_data = [X_train, y_train]\n",
    "        validation_data = [X_valid, y_valid]\n",
    "        \n",
    "        return train_data, validation_data, test_data\n",
    "\n",
    "    train_data = [X_train, y_train]\n",
    "    test_data = [X_test, y_test]\n",
    "\n",
    "    return train_data, test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"Using {device} device\")\n",
    "\n",
    "    IMG_FILES = glob(CFG.img_path + \"/*.jpg\")\n",
    "    XML_FILES = glob(CFG.xml_path + \"/*.xml\")\n",
    "\n",
    "    #\"id\", \"label\", \"xmin\", \"ymin\", \"xmax\", \"ymax\", \"img_path\"\n",
    "    df, classes = build_df(XML_FILES)\n",
    "    data = df.to_numpy()\n",
    "    # f_n = data[100][0] + '.txt'\n",
    "\n",
    "    # input and target \n",
    "    input  = df[['id','img_path']].values\n",
    "    input =np.squeeze(input)\n",
    "    # input = input.reset_index()\n",
    "    target = df[['xmin','ymin', 'xmax', 'ymax','label']].values.astype(np.int64) \n",
    "\n",
    "    train_data, validation_data, test_data = split_dataset(input,target,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10927, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9     726\n",
       " 4     723\n",
       " 6     721\n",
       " 5     719\n",
       " 8     719\n",
       " 1     719\n",
       " 7     718\n",
       " 10    717\n",
       " 0     716\n",
       " 2     716\n",
       " 3     672\n",
       " Name: 4, dtype: int64,\n",
       " 9     202\n",
       " 4     201\n",
       " 1     200\n",
       " 6     200\n",
       " 5     200\n",
       " 8     200\n",
       " 0     199\n",
       " 2     199\n",
       " 7     199\n",
       " 10    199\n",
       " 3     187\n",
       " Name: 4, dtype: int64,\n",
       " 9     81\n",
       " 8     80\n",
       " 7     80\n",
       " 4     80\n",
       " 1     80\n",
       " 0     80\n",
       " 5     80\n",
       " 10    80\n",
       " 6     80\n",
       " 2     80\n",
       " 3     74\n",
       " Name: 4, dtype: int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the split\n",
    "df = pd.DataFrame(train_data[1])\n",
    "df2 = pd.DataFrame(test_data[1])\n",
    "df3 = pd.DataFrame(validation_data[1])\n",
    "item_counts = df[4].value_counts()\n",
    "item_counts2 = df2[4].value_counts()\n",
    "item_counts3 = df3[4].value_counts()\n",
    "item_counts,item_counts2,item_counts3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(size, box):\n",
    "    dw = 1./size[0]\n",
    "    dh = 1./size[1]\n",
    "    x = (box[0] + box[1])/2.0\n",
    "    y = (box[2] + box[3])/2.0\n",
    "    w = box[1] - box[0]\n",
    "    h = box[3] - box[2]\n",
    "    x = x*dw\n",
    "    w = w*dw\n",
    "    y = y*dh\n",
    "    h = h*dh\n",
    "    return (x,y,w,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def copier(data,d_type = 'train'):\n",
    "    img_path = 'yolov7/cell_datatset/images/'\n",
    "    label_path = 'yolov7/cell_datatset/labels/'\n",
    "    i=1\n",
    "    for id, image_p, label in zip(data[0][:,0],data[0][:,1],data[1]):\n",
    "        \n",
    "\n",
    "        # Copy and paste image data\n",
    "        # read image\n",
    "        image = cv2.imread(image_p)\n",
    "        h, w, channels = image.shape\n",
    "\n",
    "        # image path + name for the copy\n",
    "        image_name = img_path + d_type +'/'+ id + '.jpg'\n",
    "\n",
    "        # Saving the image\n",
    "        cv2.imwrite(image_name, image)\n",
    "\n",
    "        \n",
    "        # SAVE LABEL DATA\n",
    "        # convert bbox -> 'xmin', 'ymin', 'xmax', 'ymax' to yolo format  (X, Y, W, H)\n",
    "        #b = (xmin, xmax, ymin, ymax)\n",
    "        b = (label[0], label[2], label[1], label[3])\n",
    "        yolo_bb = convert((w,h), b)\n",
    "        # data is made of class and bbox --->  class X Y W H\n",
    "        label_data = str(label[-1]) + \" \" + str(yolo_bb[0]) + \" \"+ str(yolo_bb[1]) + \" \"+ str(yolo_bb[2]) + \" \"+ str(yolo_bb[3])\n",
    "\n",
    "        # file_path \n",
    "        label_name = label_path + d_type +'/'+ id + '.txt'\n",
    "        # write to data.txt\n",
    "        with open(label_name, 'w') as f:\n",
    "            f.write(label_data)\n",
    "        i+=1\n",
    "        print(f\"Image: {i} Img:{image_name} \")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copier(train_data,d_type = 'train')\n",
    "# copier(validation_data,d_type = 'valid')\n",
    "# copier(test_data,d_type = 'test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "parasite_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c81684d08f7e11e8cc2690833505ff949fd5ca5b3e09514df37bdb97d1cbbdcd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
